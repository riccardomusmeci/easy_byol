model_name: byol                              # model name

dataset: CIFAR10                              # dataset to use among STL10, dogs, CIFAR10.

model:
  backbone: resnet18                          # model to use as feature extractor (supported: resnet18, resnet50, effdetb0)
  pretrained: false                           # load pretrained weights for backbone
  hidden_size: 4096                           # MLP predictor hidden units
  projection_size: 256                        # MLP output size
  beta: 0.999                                 # EMA param to update target weights

train:
  epochs: 1000                                # training epochs
  batch_size: 1024                            # batch size
  
optimizer:
  algo: adam                                  # optimization algorithm
  lr: 0.02                                    # learning rate
  weight_decay: 1.5e-6                        # weight decay                     

loss:
  type: norm_mse                              # loss type

transform: 
  img_size: 32                                # input image size
  mean: [0.5, 0.5, 0.5]                       # ImageNet mean normalization ([0.485, 0.456, 0.406])
  std: [0.5, 0.5, 0.5]                        # ImageNet std normalization ([0.229, 0.224, 0.225])
  brightness: 0.4                             # color jitter brightness
  contrast: 0.4                               # color jitter contrast
  saturation: 0.2                             # color jitter saturation
  hue: 0.1                                    # color jitter hue            
  color_jitter_p: 0.5                         # color jitter transformation probability
  grayscale_p: 0.2                            # grayscale transformation probabilty
  h_flip_p: 0.5                               # horizontal flip transformation probabilty
  kernel: [3, 3]                              # gaussian blur kernel size
  sigma: [.1, 2]                              # gaussian blur params
  gaussian_blur_p: 0.1                        # gaussian blur transformation probability

scheduler:
  algo: cosine                                # scheduler algorithm    
  cosine:                                     # cosine params
    T_max: 100                                # maximum iterations for scheduler
    eta_min: 0.00002                          # minimum learning rate
    verbose: true
  linear:                                     # linear params
    start_factor: 0.8                         # linear scaling factor at each iter
    end_factor: 1.0                           # the number we multiply learning rate at the end of linear changing process
    total_iters: 10                           # number of epochs for applying linear lr scherduling
    verbose: true